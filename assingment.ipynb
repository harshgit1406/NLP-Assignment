{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d153bdf1",
   "metadata": {},
   "source": [
    "# Task 1 – NLP Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776d34f",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1b030c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, movie_reviews\n",
    "from nltk import FreqDist, NaiveBayesClassifier\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.classify import accuracy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff86991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('movie_reviews')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fad655",
   "metadata": {},
   "source": [
    "Step 2: Input Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055ecee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph:\n",
      " Artificial Intelligence and Machine Learning are transforming the world.\n",
      "They help automate tasks, improve decision-making, and enhance user experiences across industries.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "paragraph = \"\"\"Artificial Intelligence and Machine Learning are transforming the world.\n",
    "They help automate tasks, improve decision-making, and enhance user experiences across industries.\"\"\"\n",
    "print(\"Paragraph:\\n\", paragraph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f390bf0",
   "metadata": {},
   "source": [
    "Step 3: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb3adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Tokenization:\n",
      " ['Artificial', 'Intelligence', 'and', 'Machine', 'Learning', 'are', 'transforming', 'the', 'world', '.', 'They', 'help', 'automate', 'tasks', ',', 'improve', 'decision-making', ',', 'and', 'enhance', 'user', 'experiences', 'across', 'industries', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "tokens = word_tokenize(paragraph)\n",
    "print(\"After Tokenization:\\n\", tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc504257",
   "metadata": {},
   "source": [
    "Step 4: Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9dc4637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stopword Removal:\n",
      " ['Artificial', 'Intelligence', 'Machine', 'Learning', 'transforming', 'world', 'help', 'automate', 'tasks', 'improve', 'enhance', 'user', 'experiences', 'across', 'industries']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word.isalpha()]\n",
    "\n",
    "print(\"After Stopword Removal:\\n\", filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f26d6c6",
   "metadata": {},
   "source": [
    "Step 5: Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a05e5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " After Stemming:\n",
      " ['artifici', 'intellig', 'machin', 'learn', 'transform', 'world', 'help', 'autom', 'task', 'improv', 'enhanc', 'user', 'experi', 'across', 'industri']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "stemmed_words = [ps.stem(word) for word in filtered_tokens]\n",
    "print(\"\\n After Stemming:\\n\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda5506",
   "metadata": {},
   "source": [
    "Step 6: Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31f6bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " After Lemmatization:\n",
      " ['Artificial', 'Intelligence', 'Machine', 'Learning', 'transforming', 'world', 'help', 'automate', 'task', 'improve', 'enhance', 'user', 'experience', 'across', 'industry']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "print(\"\\n After Lemmatization:\\n\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee4949",
   "metadata": {},
   "source": [
    "# Task 2 – Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c6d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c18c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reviews: 2000\n",
      "Sample Data: (['the', 'last', 'line', '(', 'or', 'near', 'to', 'that', 'honor', ')', 'is', 'the', 'great', 'butler', ',', 'alfred', '(', 'the', 'ubergod', ',', 'michael', 'gough', ')', 'saying', ',', '\"', 'i', 'think', 'we', 'need', 'a', 'bigger', 'bat', 'cave', ',', '\"', 'or', 'something', 'to', 'that', 'note', '.', 'that', \"'\", 's', 'exactly', 'what', 'this', 'film', 'is', '-', 'too', 'big', 'for', 'its', 'own', 'good', 'because', 'it', 'has', 'too', 'damn', 'much', '.', 'cut', 'batgirl', 'out', '.', 'cut', 'one', 'of', 'the', 'villains', '.', 'it', \"'\", 's', 'too', 'much', 'to', 'handle', 'in', 'one', 'dosage', '.', 'it', \"'\", 's', 'so', 'much', 'that', 'characters', 'get', 'left', 'behind', '.', 'poor', 'elle', 'gets', 'a', 'mere', '3', 'scenes', 'and', 'a', 'subplot', 'which', 'is', 'introduced', 'but', 'never', 'finished', 'in', 'any', 'way', ',', 'shape', 'or', 'form', '.', 'and', 'elle', 'deserves', 'better', '.', 'this', 'is', 'the', 'fourth', 'in', 'the', 'gigantic', 'film', 'series', 'and', 'the', 'second', 'from', 'director', 'joel', 'schumacher', '.', 'it', \"'\", 's', 'also', 'the', 'fourth', 'worst', 'in', 'the', 'series', '(', 'and', 'second', 'worst', 'from', 'joel', ')', '.', 'the', 'series', 'has', 'been', 'declining', 'since', 'its', 'stunning', 'debut', ',', 'followed', 'by', 'the', 'almost', '-', 'as', '-', 'stunning', 'sequel', 'and', 'then', 'the', 'anti', '-', 'climactic', 'third', 'one', '(', 'first', 'by', 'joel', ')', '.', 'this', 'one', \"'\", 's', 'not', 'anti', '-', 'climactic', '-', 'i', 'knew', 'it', 'was', 'gonna', 'suck', '.', 'it', \"'\", 's', 'up', 'to', 'joel', 'to', 'make', 'it', 'fun', 'though', '.', '\"', 'batman', 'forever', '\"', 'was', 'fun', '.', 'this', 'is', 'a', 'big', 'bore', 'of', 'over', '-', 'produced', 'action', 'sequences', 'and', 'shallow', 'characters', '.', 'i', 'mean', ',', 'this', 'one', 'bit', '.', 'i', \"'\", 'm', 'gonna', 'put', 'all', 'the', 'plot', 'in', 'one', 'paragraph', ':', 'mr', '.', 'freeze', '(', 'ah', '-', 'nold', ')', ',', 'who', \"'\", 's', 'wife', 'was', 'dying', 'of', 'some', 'disease', ',', 'has', 'become', 'the', 'new', 'big', 'villain', 'these', 'days', '.', 'he', \"'\", 's', 'a', 'huge', 'ex', '-', 'scientist', 'who', 'fell', 'into', 'some', 'weird', 'liquid', '(', 'hello', '?', 'joker', '?', ')', 'and', 'now', 'has', 'a', 'body', 'temperature', 'of', 'a', 'big', 'fat', 'zero', 'and', 'has', 'a', 'blue', 'body', '.', 'batman', '(', 'george', ')', 'and', 'robin', '(', 'chris', ')', 'fight', 'him', 'a', 'bit', 'but', 'find', 'they', \"'\", 're', 'growing', 'apart', '.', 'meanwhile', ',', 'another', 'villain', 'shows', 'up', ',', 'poison', 'ivy', '(', 'uma', '!', ')', ',', 'who', 'was', 'a', 'dorky', 'scientist', 'chick', 'working', 'on', 'flowers', 'in', 'south', 'america', 'with', 'a', 'twistet', 'scientist', '(', 'john', 'glover', ')', 'who', 'kills', 'her', 'when', 'she', 'finds', 'out', 'he', \"'\", 's', 'used', 'her', 'research', 'to', 'develop', 'an', 'uberman', ',', 'bane', ',', 'who', 'is', 'basically', 'a', 'man', 'pumped', 'with', 'chemicals', 'which', 'probably', 'killed', 'any', 'personality', 'he', 'ever', 'had', '.', 'she', 'emerges', 'from', 'her', 'chemicals', '(', 'don', \"'\", 't', 'ask', \"'\", 'cause', 'i', 'can', \"'\", 't', 'tell', 'ya', ')', 'as', 'a', 'sexy', 'woman', '(', 'the', 'real', 'uma', ')', 'who', \"'\", 's', 'poison', 'when', 'or', 'if', 'you', 'kiss', 'her', 'and', 'has', 'some', 'aphrodiasiatic', 'scent', 'she', 'blows', 'at', 'people', '.', 'she', 'starts', 'to', 'tear', 'away', 'at', 'the', 'dynamic', 'duo', '.', 'meanwhile', ',', 'alfred', \"'\", 's', 'dying', 'of', 'the', 'same', 'disease', 'mr', '.', 'freeze', \"'\", 's', 'wife', 'has', '(', 'but', 'in', 'an', 'earlier', 'state', 'than', 'she', ')', ',', 'and', 'his', 'niece', ',', 'barbara', '(', 'alicia', ')', ',', 'comes', 'all', 'the', 'way', 'from', 'oxford', 'without', 'an', 'english', 'accent', 'to', 'get', 'him', 'away', 'from', 'the', 'butler', 'trade', ',', 'but', 'soon', '(', 'well', ',', 'not', 'really', 'soon', ',', 'it', 'takes', 'her', '2', 'hours', ')', 'becomes', 'batgirl', '.', 'meanwhile', ',', 'in', 'an', 'unfinished', 'subplot', ',', 'bruce', '(', 'batman', \"'\", 's', 'alter', '-', 'ego', ',', 'if', 'you', 'forgot', ')', 'has', 'been', 'dating', 'the', 'lovely', 'julie', 'madison', '(', 'the', 'even', 'lovlier', 'elle', 'macpherson', ')', 'who', 'wants', 'a', 'commitment', 'after', 'a', 'year', 'but', 'he', 'says', 'nothing', '.', 'end', 'of', 'her', 'for', 'all', 'we', 'know', '.', 'mr', '.', 'freeze', 'ultimately', 'teams', 'with', 'poison', 'ivy', 'and', 'they', 'want', 'to', 'freeze', 'the', 'world', 'and', 'then', 'take', 'it', 'over', 'growing', 'new', 'plants', 'as', 'their', 'population', '(', 'don', \"'\", 't', 'ask', '!', '!', '!', ')', '.', 'the', 'trio', 'must', 'team', 'together', '\"', 'as', 'family', '\"', 'to', 'beat', 'them', '.', 'there', 'ya', 'go', '.', 'not', 'the', 'whole', 'story', 'but', 'no', 'big', 'context', 'clues', '.', 'too', 'much', ',', 'right', '?', 'right', '!', 'the', 'films', 'seems', 'patched', 'together', 'of', 'nice', 'little', 'ideas', 'which', 'would', 'have', 'made', 'for', 'a', 'couple', 'good', 'sequels', '.', 'however', ',', 'while', 'tim', 'burton', 'nicely', 'balanced', 'the', 'villain', '/', 'batman', 'storyline', '(', 'although', 'not', 'wonderfully', ')', ',', 'joel', 'seems', 'to', 'do', 'almost', 'nothing', 'with', 'batman', 'in', 'this', 'one', '.', 'he', 'gets', 'some', 'corny', 'speeches', ',', 'a', 'couple', 'clever', 'lines', 'and', 'that', \"'\", 's', 'it', '.', 'maybe', 'some', 'stunts', '.', 'for', 'all', 'this', ',', 'i', 'can', \"'\", 't', 'even', 'comment', 'on', 'george', 'clooney', 'as', 'batman', '-', 'i', 'hardly', 'saw', 'the', 'guy', '!', 'and', 'when', 'i', 'did', ',', 'he', 'had', 'horrible', 'dialogue', 'to', 'say', '.', 'i', 'think', 'michael', 'keaton', 'is', 'the', 'quintessential', 'batman', 'but', 'val', 'kilmer', 'was', 'too', 'robotic', 'and', 'fake', 'as', 'batman', 'in', 'the', 'last', 'episode', '.', 'george', 'is', 'in', 'between', 'them', '.', 'he', \"'\", 's', 'not', 'quintessential', ',', 'he', \"'\", 's', 'not', 'horrible', ',', 'he', \"'\", 's', 'good', '.', 'but', 'i', \"'\", 'm', 'sure', 'next', 'time', 'when', 'they', 'decide', 'to', 'renovate', 'the', 'series', 'since', 'they', \"'\", 'll', 'be', 'critically', 'murdered', 'for', 'this', 'sorry', 'effort', ',', 'we', \"'\", 'll', 'get', 'a', 'good', 'script', 'and', 'clooney', 'will', 'shine', '(', 'if', 'he', 'still', 'has', 'the', 'job', ')', '.', 'the', 'villains', 'are', 'the', 'only', 'interesting', 'part', 'of', 'the', 'series', 'according', 'to', 'schumacher', '.', 'last', 'time', ',', 'we', 'had', 'the', 'brawn', 'of', 'two', 'face', 'as', 'played', 'by', 'tommy', 'lee', 'jones', 'and', 'the', 'brains', '/', 'comedy', 'supplied', 'by', 'the', 'riddler', 'as', 'realized', 'by', 'jim', 'carrey', '.', 'this', 'time', 'we', 'have', 'a', 'somewhat', 'sympathetic', 'and', 'somewhat', 'hatable', 'villain', '(', 'the', 'same', 'guy', ')', ',', 'mr', '.', 'freeze', '.', 'we', 'feel', 'bad', 'for', 'his', 'mental', '/', 'physical', 'collapse', 'but', 'does', 'he', 'really', 'need', 'to', 'kill', 'everyone', 'for', 'plants', '?', 'arnold', 'isn', \"'\", 't', 'very', 'good', '-', 'too', 'hokey', 'but', 'kinda', 'sympathetic', 'at', 'some', 'points', '.', 'when', 'he', 'watches', 'old', 'movies', 'of', 'his', 'wife', ',', 'he', 'actually', 'looks', 'somber', '.', 'wow', '.', 'but', 'uma', 'makes', 'the', 'most', 'of', 'her', 'seductive', 'character', ',', 'getting', 'the', 'right', 'point', 'between', 'hamminess', 'and', 'seductiveness', '.', 'it', \"'\", 's', 'like', 'she', \"'\", 's', 'almost', 'parodying', 'herself', 'in', '\"', 'pulp', 'fiction', '\"', 'at', 'points', '.', 'she', \"'\", 's', 'incredibly', 'hot', 'and', 'makes', 'the', 'movie', 'pretty', 'much', 'a', 'star', 'better', '.', 'as', 'for', 'the', 'lower', 'bat', '-', 'people', ',', 'chris', 'is', 'the', 'same', 'as', 'he', 'was', 'in', '\"', 'batman', 'forever', ',', '\"', 'although', 'i', 'think', 'his', 'work', 'in', 'these', 'is', 'too', 'hokey', 'when', 'he', \"'\", 's', 'best', 'at', 'quieter', 'parts', 'in', '\"', 'scent', 'of', 'a', 'woman', '\"', 'or', 'just', 'plain', 'cool', 'parts', 'in', '\"', 'fried', 'green', 'tomotoes', '.', '\"', 'alicia', '-', 'i', 'love', 'the', 'girl', 'but', 'she', \"'\", 's', 'not', 'particularly', 'good', 'in', 'this', 'film', '.', 'she', 'can', 'hypotheitically', 'act', ',', 'we', 'all', 'saw', 'that', 'in', '\"', 'clueless', ',', '\"', 'but', 'her', 'lines', 'kinda', 'sound', 'weird', '.', 'and', 'it', 'isn', \"'\", 't', 'the', 'mushy', '-', 'mouth', 'this', 'time', '.', 'but', 'in', 'all', 'fairness', ',', 'she', 'has', 'virtually', 'no', 'part', '.', 'joel', 'gets', 'around', 'to', 'her', 'occasionally', 'and', 'when', 'she', \"'\", 's', 'on', ',', 'she', 'does', 'stupid', 'stuff', '.', '.', '.', 'although', 'i', 'know', 'i', \"'\", 'm', 'not', 'the', 'only', 'one', 'who', 'loved', 'the', 'catfight', 'between', 'her', 'and', 'uma', '.', '.', '.', 'and', 'poor', 'elle', '.', 'poor', ',', 'poor', 'elle', '.', 'i', 'love', 'that', 'woman', 'and', 'she', 'can', 'also', 'hypothetically', 'act', '(', 'for', 'those', 'of', 'us', 'who', 'saw', '\"', 'sirens', '\"', ')', '.', 'but', 'she', 'has', 'no', 'part', '!', '!', '!', 'it', 'seems', 'like', 'joel', 'had', 'so', 'much', 'footage', 'that', 'he', 'had', 'to', 'edit', 'almost', 'an', 'hour', 'out', 'of', 'the', 'final', 'product', '.', 'there', 'are', 'no', '\"', 'couch', '\"', 'scenes', '(', 'like', 'my', 'best', 'friend', 'noticed', ')', '.', 'now', 'listen', 'to', 'me', 'on', 'this', 'one', '-', 'in', 'every', '\"', 'batman', '\"', 'flick', ',', 'there', \"'\", 's', 'a', 'couch', 'scene', '.', 'in', 'the', 'original', ',', 'it', 'was', 'with', 'vicki', '.', 'in', '\"', 'returns', ',', '\"', 'it', 'was', 'a', 'good', 'make', '-', 'out', 'scene', 'with', 'selena', '.', 'and', 'in', 'the', 'last', 'one', ',', 'it', 'was', 'a', 'chat', 'with', 'nicole', '.', 'this', 'one', ',', 'it', \"'\", 's', 'nothing', '.', 'and', 'batgirl', 'does', 'next', '-', 'to', '-', 'nothing', 'in', 'this', 'film', 'till', 'the', 'end', 'when', 'she', \"'\", 's', 'suddenly', '\"', 'part', 'of', 'the', 'family', '.', '\"', 'fortunately', ',', 'we', 'get', 'a', 'lot', 'of', 'alfred', '.', 'he', \"'\", 's', 'the', 'always', 'reliable', 'butler', ',', 'in', 'case', 'you', 'didn', \"'\", 't', 'know', ',', 'who', 'has', 'been', 'with', 'bruce', 'all', 'his', 'life', '.', 'he', \"'\", 's', 'a', 'god', '.', 'he', \"'\", 's', 'a', 'father', 'figure', '.', 'he', \"'\", 's', 'also', 'dying', '.', 'this', 'got', 'to', 'me', '.', 'i', 'love', 'alfred', 'almost', 'as', 'much', 'as', 'bruce', 'and', 'to', 'see', 'him', 'in', 'a', 'robe', ',', 'not', 'in', 'his', 'tux', ',', 'and', 'freaking', 'dying', 'just', 'gets', 'to', 'me', '.', 'we', 'also', 'get', 'the', 'idea', 'that', 'he', 'might', 'have', 'been', 'unhappy', 'the', 'whole', 'time', '.', '.', '.', 'but', 'this', 'is', 'never', 'answered', ',', 'as', 'this', 'film', 'is', 'too', 'cluttered', '.', 'but', 'in', 'defense', ',', 'it', 'does', 'have', 'some', 'good', 'parts', ',', 'other', 'than', 'uma', '.', 'for', 'one', ',', 'george', 'is', 'a', 'good', 'batman', 'but', 'unfortunately', 'gets', 'nothing', 'to', 'do', '.', 'and', 'there', 'are', 'some', 'nice', 'touches', '.', 'when', 'they', 'show', 'the', 'asylum', 'at', 'one', 'point', ',', 'they', 'show', 'the', 'patient', \"'\", 's', 'belongings', 'in', 'a', 'room', 'and', 'we', 'see', 'the', 'riddler', \"'\", 's', 'costume', '.', 'i', 'laughed', '.', 'and', 'during', 'a', 'biker', 'scene', '(', 'involving', 'robin', 'and', 'batgirl', '-', 'another', 'subplot', 'never', 'handled', 'past', 'initiation', 'period', ')', ',', 'we', 'not', 'only', 'see', 'coolio', 'but', 'a', 'bunch', 'of', 'bad', '-', 'asses', 'dressed', 'as', '\"', 'droogs', '\"', 'from', '\"', 'a', 'clockwork', 'orange', '.', '\"', 'i', 'laughed', 'at', 'all', 'these', '.', 'the', 'film', 'falls', 'apart', 'around', 'the', 'five', '-', 'minute', 'mark', 'during', 'an', 'enormously', 'long', 'action', 'sequence', 'which', 'must', 'last', 'around', '20', 'minutes', '.', '.', '.', 'or', 'did', 'it', 'just', 'feel', 'like', 'that', '?', 'the', 'film', 'should', 'serve', 'as', 'another', 'in', 'the', 'long', '-', 'line', 'of', 'films', 'which', 'demonstrate', 'that', 'we', 'need', 'more', 'intelligent', 'films', 'nowadays', '.', 'people', 'are', 'fed', 'up', 'with', 'stupid', 'films', '.', 'that', \"'\", 's', 'why', 'the', 'word', 'of', 'mouth', 'killed', '\"', 'the', 'lost', 'world', '!', '\"', 'that', \"'\", 's', 'why', 'last', 'year', ',', 'indy', 'films', 'grossed', 'more', 'than', 'ever', '.', 'that', \"'\", 's', 'why', 'this', 'will', 'have', 'a', 'strong', 'box', '-', 'office', 'initative', 'from', 'people', 'who', 'just', 'want', 'to', 'see', 'it', ',', 'like', 'me', ',', 'but', 'will', 'die', 'after', 'a', 'week', 'or', 'two', 'when', 'the', 'word', 'around', 'the', 'grapevine', 'kills', 'it', '.', 'that', \"'\", 's', 'why', 'the', 'next', 'two', 'big', '-', 'budget', 'aciton', 'pics', 'are', 'john', 'woo', \"'\", 's', '\"', 'face', '/', 'off', '\"', 'and', 'barry', 'sonnenfeld', \"'\", 's', '\"', 'men', 'in', 'black', ',', '\"', 'both', 'which', 'are', 'the', 'first', 'two', 'to', 'catch', 'on', 'to', 'the', 'wave', 'early', 'on', '.', 'i', 'like', 'joel', 'schumacher', 'more', 'as', 'a', 'person', 'than', 'an', 'artiste', '.', 'i', 'like', 'some', 'of', 'his', 'films', '(', '\"', 'flatliners', ',', '\"', '\"', 'a', 'time', 'to', 'kill', '\"', ')', 'but', 'a', 'lot', 'of', 'them', 'suck', '.', 'he', \"'\", 's', 'a', 'really', 'eccentric', 'person', 'and', 'i', 'loved', 'one', 'of', 'his', 'quotes', 'about', 'how', 'he', 'admits', 'to', 'being', 'a', 'mediocre', 'director', 'and', 'that', \"'\", 's', 'what', 'makes', 'him', 'great', '.', 'but', 'his', 'costuming', 'for', 'woody', 'allen', \"'\", 's', '\"', 'sleeper', '\"', 'was', 'more', 'interesting', 'than', 'this', 'one', '(', 'and', 'his', 'costuming', 'was', 'cool', '-', 'look', 'for', 'the', 'nazi', 'number', ')', '.', 'i', 'love', 'the', '\"', 'batman', '\"', 'series', '.', 'the', 'first', 'two', 'rocked', 'and', 'i', 'did', 'like', 'the', 'last', 'one', '.', 'but', 'this', 'one', 'is', 'not', 'going', 'to', 'be', 'one', 'that', 'i', 'watch', 'repeatedly', 'like', 'the', 'other', 'three', '.', 'hopefully', ',', 'this', 'will', 'also', 'serve', 'as', 'a', 'springboard', 'to', 'a', 'better', 'batman', 'next', 'time', '.', 'and', 'maybe', 'they', \"'\", 'll', 'get', 'smart', 'and', 'bring', 'back', 'catwoman', '.', 'and', 'michael', 'keaton', '.', 'but', 'we', 'can', 'only', 'hope', '.'], 'neg')\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(documents)\n",
    "\n",
    "print(\"Total Reviews:\", len(documents))\n",
    "print(\"Sample Data:\", documents[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0ae8580",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = FreqDist(w.lower() for w in movie_reviews.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30dec622",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words)[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4486e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[f'contains({word})'] = (word in words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72b1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d, c) in documents]\n",
    "train_set, test_set = featuresets[:1600], featuresets[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b18d1130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.805\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =      8.3 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      7.2 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      7.1 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      6.1 : 1.0\n",
      "        contains(poorly) = True              neg : pos    =      5.8 : 1.0\n",
      "        contains(wasted) = True              neg : pos    =      5.8 : 1.0\n",
      "         contains(awful) = True              neg : pos    =      5.7 : 1.0\n",
      "         contains(waste) = True              neg : pos    =      5.5 : 1.0\n",
      "           contains(era) = True              pos : neg    =      5.1 : 1.0\n",
      "            contains(it) = False             neg : pos    =      5.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes classifier\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Accuracy:\", accuracy(classifier, test_set))\n",
    "\n",
    "# Show most informative words\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08e90c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: neg\n"
     ]
    }
   ],
   "source": [
    "test_text = \"The movie was fantastic! The performances were amazing and the story was touching.\"\n",
    "custom_features = document_features(test_text.split())\n",
    "print(\"Predicted Sentiment:\", classifier.classify(custom_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a8bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
